<div class="Box-sc-g0xbh4-0 QkQOb js-snippet-clipboard-copy-unpositioned" data-hpc="true"><article class="markdown-body entry-content container-lg" itemprop="text"><div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto" _msttexthash="36836813" _msthash="277">涡轮飞行员 🚀</h1><a id="user-content-turbopilot-" class="anchor" aria-label="永久链接：TurboPilot 🚀" href="#turbopilot-" _mstaria-label="40603589" _msthash="278"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="1119530100" _msthash="279">Turbopilot 已弃用/存档于 30 年 9 月 23 日。还有其他成熟的解决方案可以更好地满足社区的需求。请阅读<a href="https://brainsteam.co.uk/posts/2023/09/30/turbopilot-obit/" rel="nofollow" _istranslated="1">我的博客文章</a>，了解我决定关闭工具并推荐替代方案。</h2><a id="user-content-turbopilot-is-deprecatedarchived-as-of-30923-there-are-other-mature-solutions-that-meet-the-communitys-needs-better-please-read-my-blog-post-about-my-decision-to-down-tools-and-for-recommended-alternatives" class="anchor" aria-label="永久链接：Turbopilot 已弃用/存档于 30 年 9 月 23 日。还有其他成熟的解决方案可以更好地满足社区的需求。请阅读我的博客文章，了解我决定关闭工具并推荐替代方案。" href="#turbopilot-is-deprecatedarchived-as-of-30923-there-are-other-mature-solutions-that-meet-the-communitys-needs-better-please-read-my-blog-post-about-my-decision-to-down-tools-and-for-recommended-alternatives" _mstaria-label="26517101" _msthash="280"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<hr>
<p dir="auto"><a href="https://fosstodon.org/@jamesravey" rel="nofollow"><img src="https://camo.githubusercontent.com/e712955f3fbcebbdf15ff78c46b026a0833e0d82d78bb4bc79b9cad63c35f81c/68747470733a2f2f696d672e736869656c64732e696f2f6d6173746f646f6e2f666f6c6c6f772f3030303131373031323f646f6d61696e3d6874747073253341253246253246666f7373746f646f6e2e6f7267253246267374796c653d736f6369616c" alt="Mastodon 关注" data-canonical-src="https://img.shields.io/mastodon/follow/000117012?domain=https%3A%2F%2Ffosstodon.org%2F&amp;style=social" style="max-width: 100%;" _mstalt="260117" _msthash="281"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/9bff33fb5c65db0ee02b66ad5a8cbd40b5e28f14a0b8a1e228922f8ba8cccb3a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f726176656e7363726f66746a2f747572626f70696c6f74"><img src="https://camo.githubusercontent.com/9bff33fb5c65db0ee02b66ad5a8cbd40b5e28f14a0b8a1e228922f8ba8cccb3a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f726176656e7363726f66746a2f747572626f70696c6f74" alt="BSD 许可" data-canonical-src="https://img.shields.io/github/license/ravenscroftj/turbopilot" style="max-width: 100%;" _mstalt="165555" _msthash="282"></a> <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/ce1d7fe9b75faf27fc9c388d1ff3c5eeb2a352a8dff4b44987f8be2adaa17d39/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e743f75726c3d68747470733a2f2f77616b6170692e6e6f70726f2e62652f6170692f636f6d7061742f736869656c64732f76312f6a616d657372617665792f616c6c5f74696d652f6c6162656c253341747572626f70696c6f74"><img src="https://camo.githubusercontent.com/ce1d7fe9b75faf27fc9c388d1ff3c5eeb2a352a8dff4b44987f8be2adaa17d39/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e743f75726c3d68747470733a2f2f77616b6170692e6e6f70726f2e62652f6170692f636f6d7061742f736869656c64732f76312f6a616d657372617665792f616c6c5f74696d652f6c6162656c253341747572626f70696c6f74" alt="逗留时间" data-canonical-src="https://img.shields.io/endpoint?url=https://wakapi.nopro.be/api/compat/shields/v1/jamesravey/all_time/label%3Aturbopilot" style="max-width: 100%;" _mstalt="133497" _msthash="283"></a></p>
<p dir="auto" _msttexthash="1045465824" _msthash="284">TurboPilot 是一个自托管的 <a href="https://github.com/features/copilot" _istranslated="1">copilot</a> 克隆，它使用 <a href="https://github.com/ggerganov/llama.cpp" _istranslated="1">llama.cpp</a> 背后的库在 4GiB 的 RAM 中运行 <a href="https://github.com/salesforce/CodeGen" _istranslated="1">60 亿个参数的 Salesforce Codegen 模型</a>。它在很大程度上基于 <a href="https://github.com/fauxpilot/fauxpilot" _istranslated="1">fauxpilot</a> 项目并受到其启发。</p>
<p dir="auto"><em><strong _msttexthash="827370895" _msthash="285">注意：这是目前的概念验证，而不是一个稳定的工具。在此版本的项目中，自动完成速度非常慢。随意玩它，但您的里程可能会有所不同。</strong></em></p>
<p dir="auto"><animated-image data-catalyst=""><a target="_blank" rel="noopener noreferrer" href="/ravenscroftj/turbopilot/blob/main/assets/vscode-status.gif" data-target="animated-image.originalLink"><img src="/ravenscroftj/turbopilot/raw/main/assets/vscode-status.gif" alt="通过 FauxPilot 插件运行的 Turbopilot 的屏幕录像" style="max-width: 100%; display: inline-block;" data-target="animated-image.originalImage" _mstalt="2834455" _msthash="286"></a>
      
<p dir="auto"><font _mstmutation="1" _msttexthash="213105191" _msthash="291"><strong _mstmutation="1" _istranslated="1">✨ 现在支持 <a href="https://huggingface.co/stabilityai/stablecode-instruct-alpha-3b" rel="nofollow" _istranslated="1">StableCode 3B Instruct</a></strong> 只需使用 <a href="https://huggingface.co/TheBloke/stablecode-instruct-alpha-3b-GGML" rel="nofollow" _mstmutation="1" _istranslated="1">TheBloke 的量化 GGML 模型</a>并设置 .</font><code>-m stablecode</code></p>
<p dir="auto" _msttexthash="638417169" _msthash="292"><strong _istranslated="1">✨ 新增内容：重构 + 简化</strong>：源代码已得到改进，可以更轻松地扩展和添加新模型到 Turbopilot。该系统现在支持多种风格的模型</p>
<p dir="auto" _msttexthash="1101254882" _msthash="293"><strong _istranslated="1">✨ 新增：Wizardcoder、Starcoder、Santacoder 支持</strong> - Turbopilot 现在支持最先进的本地代码完成模型，这些模型提供了更多的编程语言和“中间填充”支持。</p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="18984771" _msthash="294">🤝 贡献</h2><a id="user-content--contributing" class="anchor" aria-label="永久链接： 🤝 贡献" href="#-contributing" _mstaria-label="26033826" _msthash="295"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="79002924" _msthash="296">非常欢迎此项目的 PR 和相应的 <a href="https://github.com/ravenscroftj/ggml" _istranslated="1">GGML 分叉</a>。</p>
<p dir="auto" _msttexthash="100644115" _msthash="297">创建一个 fork，进行更改，然后打开 <a href="https://github.com/ravenscroftj/turbopilot/pulls" _istranslated="1">PR。</a></p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="16736317" _msthash="298">👋 开始</h2><a id="user-content--getting-started" class="anchor" aria-label="永久链接： 👋 开始使用" href="#-getting-started" _mstaria-label="26059462" _msthash="299"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="262630446" _msthash="300">试用该项目的最简单方法是获取预处理的模型，然后在 docker 中运行服务器。</p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="11392680" _msthash="301">获取模型</h3><a id="user-content-getting-the-models" class="anchor" aria-label="永久链接：获取模型" href="#getting-the-models" _mstaria-label="665795" _msthash="302"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="44363241" _msthash="303">您有 2 个选项来获取模型</p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto" _msttexthash="80805101" _msthash="304">选项 A：直接下载 - 简单、快速入门</h4><a id="user-content-option-a-direct-download---easy-quickstart" class="anchor" aria-label="永久链接：选项 A：直接下载 - 简单、快速" href="#option-a-direct-download---easy-quickstart" _mstaria-label="1887587" _msthash="305"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="138583822" _msthash="306">您可以从 Huggingface 下载预转换、预量化的模型。</p>
<p dir="auto" _msttexthash="567365370" _msthash="307">对于低 RAM 用户（4-8 GiB），我推荐 <a href="https://huggingface.co/TheBloke/stablecode-instruct-alpha-3b-GGML" rel="nofollow" _istranslated="1">StableCode</a>，对于高功率用户（16+ GiB RAM、独立 GPU 或 Apple Silicon），我推荐 <a href="https://huggingface.co/TheBloke/WizardCoder-15B-1.0-GGML/resolve/main/WizardCoder-15B-1.0.ggmlv3.q4_0.bin" rel="nofollow" _istranslated="1">WizardCoder</a>。</p>
<p dir="auto"><font _mstmutation="1" _msttexthash="353017483" _msthash="308">Turbopilot 仍然支持早期版本的第一代 codegen 模型。尽管旧模型确实需要重新量化。</font><code>v0.0.5</code></p>
<p dir="auto" _msttexthash="93160964" _msthash="309">您可以在 <a href="/ravenscroftj/turbopilot/blob/main/MODELS.md" _istranslated="1">MODELS.md</a> 中找到完整的型号目录。</p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto" _msttexthash="101689484" _msthash="310">选项 B：自己转换模型 - 更难，更灵活</h4><a id="user-content-option-b-convert-the-models-yourself---hard-more-flexible" class="anchor" aria-label="永久链接：选项 B：自己转换模型 - 更难，更灵活" href="#option-b-convert-the-models-yourself---hard-more-flexible" _mstaria-label="2809066" _msthash="311"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="122308303" _msthash="312">如果您想尝试自己量化模型，请遵循<a href="https://github.com/ravenscroftj/turbopilot/wiki/Converting-and-Quantizing-The-Models" _istranslated="1">本指南</a>。</p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="36584015" _msthash="313">⚙️ 运行 TurboPilot 服务器</h3><a id="user-content-️-running-turbopilot-server" class="anchor" aria-label="永久链接：⚙️运行 TurboPilot 服务器" href="#️-running-turbopilot-server" _mstaria-label="18493020" _msthash="314"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="913901573" _msthash="315">下载<a href="https://github.com/ravenscroftj/turbopilot/releases" _istranslated="1">最新的二进制文件</a>并将其解压缩到根项目文件夹。如果您的操作系统没有提供二进制文件，或者您希望自己构建它，请按照<a href="/ravenscroftj/turbopilot/blob/main/BUILD.md" _istranslated="1">构建说明</a>进行操作</p>
<p dir="auto" _msttexthash="10095579" _msthash="316">跑：</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>./turbopilot -m starcoder -f ./models/santacoder-q4_0.bin</pre><div class="zeroclipboard-container">
    
  </div></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="1518269402" _msthash="317">应用程序应该在 port 上启动一个服务器，您可以使用该选项更改此设置，但这是 vscode-fauxpilot 尝试连接的默认端口，因此除非您确定自己知道自己在做什么，否则您可能希望不理会它。</font><code>18080</code><code>-p</code></p>
<p dir="auto"><font _mstmutation="1" _msttexthash="583620401" _msthash="318">如果您有一个多核系统，您可以使用该选项控制使用多少个 CPU - 例如，在我的 AMD Ryzen 5000 上，我使用 6 个内核/12 个线程：</font><code>-t</code></p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>./codegen-serve -t 6 -m starcoder -f ./models/santacoder-q4_0.bin</pre><div class="zeroclipboard-container">
   
  </div></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="116982294" _msthash="319">运行旧版 codegen 模型。只需将 model type 标志更改为 instead。</font><code>-m</code><code>codegen</code></p>
<p dir="auto"><strong _msttexthash="768649076" _msthash="320">注意：Turbopilot 0.1.0 及更高版本会重新量化 v0.0.5 及更早版本中的 codegen 模型和旧模型。我正在努力提供更新的量化代码生成模型</strong></p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="28746757" _msthash="321">📦 从 Docker 运行</h3><a id="user-content--running-from-docker" class="anchor" aria-label="永久链接：📦从 Docker 运行" href="#-running-from-docker" _mstaria-label="26224679" _msthash="322"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="101338588" _msthash="323">您还可以从<a href="https://github.com/users/ravenscroftj/packages/container/package/turbopilot" _istranslated="1">此处</a>提供的预构建 docker 映像运行 Turbopilot</p>
<p dir="auto" _msttexthash="134966988" _msthash="324">您仍然需要单独下载模型，然后才能运行：</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>docker run --rm -it \
  -v ./models:/models \
  -e THREADS=6 \
  -e MODEL_TYPE=starcoder \
  -e MODEL=<span class="pl-s"><span class="pl-pds">"</span>/models/santacoder-q4_0.bin<span class="pl-pds">"</span></span> \
  -p 18080:18080 \
  ghcr.io/ravenscroftj/turbopilot:latest</pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="docker run --rm -it \
  -v ./models:/models \
  -e THREADS=6 \
  -e MODEL_TYPE=starcoder \
  -e MODEL=&quot;/models/santacoder-q4_0.bin&quot; \
  -p 18080:18080 \
  ghcr.io/ravenscroftj/turbopilot:latest" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto" _msttexthash="3790566" _msthash="325">Docker 和 CUDA</h4><a id="user-content-docker-and-cuda" class="anchor" aria-label="永久链接： Docker 和 CUDA" href="#docker-and-cuda" _mstaria-label="497718" _msthash="326"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="1391403793" _msthash="327">从 v0.0.5 版本开始，turbocode 现在支持 CUDA 推理。为了运行启用了 cuda 的容器，您需要启用 <a href="https://github.com/NVIDIA/nvidia-docker" _mstmutation="1" _istranslated="1">nvidia-docker</a>，使用 cuda 标记的版本并传递给具有 GPU 访问权限的 docker，如下所示：</font><code>--gpus=all</code></p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>docker run --gpus=all --rm -it \
  -v ./models:/models \
  -e THREADS=6 \
  -e MODEL_TYPE=starcoder \
  -e MODEL=<span class="pl-s"><span class="pl-pds">"</span>/models/santacoder-q4_0.bin<span class="pl-pds">"</span></span> \
  -e GPU_LAYERS=32 \
  -p 18080:18080 \
  ghcr.io/ravenscroftj/turbopilot:v0.2.0-cuda11-7</pre><div class="zeroclipboard-container">
    
  </div></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="688822901" _msthash="328">如果您拥有足够大的 GPU，则设置将允许 turbopilot 将计算完全卸载到 GPU 上，而不是前后复制数据，从而大大加快推理速度。</font><code>GPU_LAYERS</code></p>
<p dir="auto"><font _mstmutation="1" _msttexthash="106395718" _msthash="329">如果您分别使用 CUDA 12.0 或 12.2，请换用 CUDA 12.0 或 12.2。</font><code>ghcr.io/ravenscroftj/turbopilot:v0.1.0-cuda11</code><code>ghcr.io/ravenscroftj/turbopilot:v0.2.0-cuda12-0</code><code>ghcr.io/ravenscroftj/turbopilot:v0.2.0-cuda12-2</code></p>
<p dir="auto"><font _mstmutation="1" _msttexthash="138307611" _msthash="330">稍后您将需要 CUDA 11 或 CUDA 12 来运行此容器。在运行 .</font><code>/app/turbopilot</code><code>nvidia-smi</code></p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto" _msttexthash="18357014" _msthash="331">可执行文件和 CUDA</h4><a id="user-content-executable-and-cuda" class="anchor" aria-label="永久链接：可执行文件和 CUDA" href="#executable-and-cuda" _mstaria-label="663000" _msthash="332"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="1324888877" _msthash="333">从 v0.0.5 开始，可以使用linux可执行文件的CUDA版本-它需要在计算机上安装libcublas 11-我可能会在某个时候构建ubuntu debs，但现在如果您想使用CUDA GPU，在docker中运行可能会更方便。</p>
<p dir="auto"><font _mstmutation="1" _msttexthash="65191789" _msthash="334">您可以通过该选项使用 GPU 卸载。</font><code>--ngl</code></p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto" _msttexthash="17290351" _msthash="335">🌐 使用 API</h3><a id="user-content--using-the-api" class="anchor" aria-label="永久链接：🌐使用 API" href="#-using-the-api" _mstaria-label="26068120" _msthash="336"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto" _msttexthash="22229012" _msthash="337">支持官方 Copilot 插件</h4><a id="user-content-support-for-the-official-copilot-plugin" class="anchor" aria-label="永久链接：支持官方 Copilot 插件" href="#support-for-the-official-copilot-plugin" _mstaria-label="1707108" _msthash="338"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="420207788" _msthash="339">对官方 VS Code copilot 插件的支持正在进行中（请参阅票证 #11）。API 现在应该与 OpenAI 广泛兼容。</p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto" _msttexthash="51999844" _msthash="340">将 API 与 FauxPilot 插件一起使用</h4><a id="user-content-using-the-api-with-fauxpilot-plugin" class="anchor" aria-label="永久链接：将 API 与 FauxPilot 插件一起使用" href="#using-the-api-with-fauxpilot-plugin" _mstaria-label="1402752" _msthash="341"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto" _msttexthash="496015299" _msthash="342">要使用 VSCode 的 API，我建议使用 vscode-fauxpilot 插件。安装后，您需要更改 settings.json 文件中的一些设置。</p>
<ul dir="auto">
<li><font _mstmutation="1" _msttexthash="80330887" _msthash="343">打开设置 （CTRL/CMD + SHIFT + P） 并选择</font><code>Preferences: Open User Settings (JSON)</code></li>
<li _msttexthash="22847188" _msthash="344">添加以下值：</li>
</ul>
<div class="highlight highlight-source-json notranslate position-relative overflow-auto" dir="auto"><pre>{
    <span class="pl-ii">... // other settings</span>

    <span class="pl-ent">"fauxpilot.enabled"</span>: <span class="pl-c1">true</span>,
    <span class="pl-ent">"fauxpilot.server"</span>: <span class="pl-s"><span class="pl-pds">"</span>http://localhost:18080/v1/engines<span class="pl-pds">"</span></span>,
}</pre><div class="zeroclipboard-container">
   
  </div></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="50858743" _msthash="345">现在，您可以使用 和 select 启用 fauxpilot</font><code>CTRL + SHIFT + P</code><code>Enable Fauxpilot</code></p>
<p dir="auto"><font _mstmutation="1" _msttexthash="652460978" _msthash="346">当您敲击键盘时，该插件将向正在运行的进程发送 API 调用。然后，它将等待每个请求完成，然后再发送进一步的请求。</font><code>codegen-serve</code></p>
<div class="markdown-heading" dir="auto"><h4 tabindex="-1" class="heading-element" dir="auto" _msttexthash="13550771" _msthash="347">直接调用 API</h4><a id="user-content-calling-the-api-directly" class="anchor" aria-label="永久链接：直接调用 API" href="#calling-the-api-directly" _mstaria-label="878345" _msthash="348"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><font _mstmutation="1" _msttexthash="175168799" _msthash="349">您可以对其发出请求，其行为与相同的 Copilot 终端节点类似。</font><code>http://localhost:18080/v1/engines/codegen/completions</code></p>
<p dir="auto" _msttexthash="11876891" _msthash="350">例如：</p>
<div class="highlight highlight-source-shell notranslate position-relative overflow-auto" dir="auto"><pre>curl --request POST \
  --url http://localhost:18080/v1/engines/codegen/completions \
  --header <span class="pl-s"><span class="pl-pds">'</span>Content-Type: application/json<span class="pl-pds">'</span></span> \
  --data <span class="pl-s"><span class="pl-pds">'</span>{</span>
<span class="pl-s"> "model": "codegen",</span>
<span class="pl-s"> "prompt": "def main():",</span>
<span class="pl-s"> "max_tokens": 100</span>
<span class="pl-s">}<span class="pl-pds">'</span></span></pre><div class="zeroclipboard-container">
    
  </div></div>
<p dir="auto" _msttexthash="56543058" _msthash="351">应该会得到这样的结果：</p>
<div class="highlight highlight-source-json notranslate position-relative overflow-auto" dir="auto"><pre>{
 <span class="pl-ent">"choices"</span>: [
  {
   <span class="pl-ent">"logprobs"</span>: <span class="pl-c1">null</span>,
   <span class="pl-ent">"index"</span>: <span class="pl-c1">0</span>,
   <span class="pl-ent">"finish_reason"</span>: <span class="pl-s"><span class="pl-pds">"</span>length<span class="pl-pds">"</span></span>,
   <span class="pl-ent">"text"</span>: <span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\n</span>  <span class="pl-cce">\"\"\"</span>Main entry point for this script.<span class="pl-cce">\"\"\"\n</span>  logging.getLogger().setLevel(logging.INFO)<span class="pl-cce">\n</span>  logging.basicConfig(format=('%(levelname)s: %(message)s'))<span class="pl-cce">\n\n</span>  parser = argparse.ArgumentParser(<span class="pl-cce">\n</span>      description=__doc__,<span class="pl-cce">\n</span>      formatter_class=argparse.RawDescriptionHelpFormatter,<span class="pl-cce">\n</span>      epilog=__doc__)<span class="pl-cce">\n</span>  <span class="pl-pds">"</span></span>
  }
 ],
 <span class="pl-ent">"created"</span>: <span class="pl-c1">1681113078</span>,
 <span class="pl-ent">"usage"</span>: {
  <span class="pl-ent">"total_tokens"</span>: <span class="pl-c1">105</span>,
  <span class="pl-ent">"prompt_tokens"</span>: <span class="pl-c1">3</span>,
  <span class="pl-ent">"completion_tokens"</span>: <span class="pl-c1">102</span>
 },
 <span class="pl-ent">"object"</span>: <span class="pl-s"><span class="pl-pds">"</span>text_completion<span class="pl-pds">"</span></span>,
 <span class="pl-ent">"model"</span>: <span class="pl-s"><span class="pl-pds">"</span>codegen<span class="pl-pds">"</span></span>,
 <span class="pl-ent">"id"</span>: <span class="pl-s"><span class="pl-pds">"</span>01d7a11b-f87c-4261-8c03-8c78cbe4b067<span class="pl-pds">"</span></span>
}</pre><div class="zeroclipboard-container">
    
  </div></div>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="26492115" _msthash="352">👉 已知限制</h2><a id="user-content--known-limitations" class="anchor" aria-label="永久链接：👉已知限制" href="#-known-limitations" _mstaria-label="26162994" _msthash="353"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li _msttexthash="275931318" _msthash="354">目前 Turbopilot 一次只支持一个 GPU 设备（它不会尝试使用多个设备）。</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto" _msttexthash="19157333" _msthash="355">👏 确认</h2><a id="user-content--acknowledgements" class="anchor" aria-label="永久链接： 👏 致谢" href="#-acknowledgements" _mstaria-label="26160225" _msthash="356"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li _msttexthash="308898044" _msthash="357">如果没有 <a href="https://github.com/ggerganov/ggml" _istranslated="1">Georgi Gerganov 在 GGML 和 llama.cpp 方面的工作</a>，这个项目是不可能的</li>
<li _msttexthash="422490107" _msthash="358">它完全受到 <a href="https://github.com/fauxpilot/fauxpilot" _istranslated="1">fauxpilot</a> 的启发，我确实尝试了一段时间，但想尝试让模型在没有 GPU 的情况下工作</li>
<li _msttexthash="109936281" _msthash="359">该项目的前端由 <a href="https://github.com/Venthe/vscode-fauxpilot" _istranslated="1">Venthe 的 vscode-fauxpilot 插件</a>提供支持</li>
<li _msttexthash="42200236" _msthash="360">该项目使用 <a href="https://github.com/salesforce/CodeGen" _istranslated="1">Salesforce Codegen</a> 模型。</li>
<li _msttexthash="1054294176" _msthash="361">感谢 <a href="https://huggingface.co/moyix" rel="nofollow" _istranslated="1">Moyix</a> 在将 Salesforce 模型转换为在 GPT-J 架构中运行所做的工作。这不仅<a href="https://gist.github.com/moyix/7896575befbe1b99162ccfec8d135566" _istranslated="1">带来了一些速度优势</a>，而且还使我更容易使用<a href="https://github.com/ggerganov/ggml/tree/master/examples/gpt-j" _istranslated="1">现有的 gpt-j 示例代码</a>将模型移植到 GGML</li>
<li _msttexthash="66174771" _msthash="362">模型服务器使用 <a href="https://crowcpp.org/master/" rel="nofollow" _istranslated="1">CrowCPP</a> 来提供建议。</li>
<li _msttexthash="115091873" _msthash="363">查看 CodeGen <a href="https://arxiv.org/pdf/2203.13474.pdf" rel="nofollow" _istranslated="1">的原始科学论文</a>以获取更多信息。</li>
</ul>
</article></div>
